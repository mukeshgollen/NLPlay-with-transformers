{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMduDADRYKvTDHQcyMheAb9"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE1mzhxrcfWP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QzcZezKc2w1",
        "outputId": "a0892b30-2bfb-43b5-840e-b28157e2bfe3"
      },
      "source": [
        "cd /content/drive/MyDrive/archive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/archive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsDIC-82dwUF"
      },
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFuqK_zJd7BJ"
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J9P-rxmeftb",
        "outputId": "294884a8-f448-4f25-f823-f1c2284e0ddd"
      },
      "source": [
        "print(data.head(10))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5  Probably my all-time favorite movie, a story o...  positive\n",
            "6  I sure would like to see a resurrection of a u...  positive\n",
            "7  This show was an amazing, fresh & innovative i...  negative\n",
            "8  Encouraged by the positive comments about this...  negative\n",
            "9  If you like original gut wrenching laughter yo...  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoBkyEmX5aJ"
      },
      "source": [
        " Let us first convert the sentiments into a form that could be understood by the computer. We can do it by assigning 1 value to positive sentiment and 0 value for negative sentiment \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2TxkGWlYUnn"
      },
      "source": [
        "def Sentiment_conversion(sentiment):\n",
        "  if sentiment =='positive':\n",
        "    return  1\n",
        "  else : return 0 "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIJmfOKUewC8"
      },
      "source": [
        "data['sentiment'] = [Sentiment_conversion(sentiment) for sentiment in data['sentiment']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QbMoeILZ4ka",
        "outputId": "7cd3394e-8af2-4eae-ba07-25843d341f3e"
      },
      "source": [
        "print(data['sentiment'].head(10))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "4    1\n",
            "5    1\n",
            "6    1\n",
            "7    0\n",
            "8    0\n",
            "9    1\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHw-jPmUaTr_",
        "outputId": "ce55cf88-8d89-42b5-b7a5-2a27698dc29e"
      },
      "source": [
        "print(pd.value_counts(data['sentiment']))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    25000\n",
            "0    25000\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vV1QTkAdcCS"
      },
      "source": [
        "We have equal numbers of sentiments distributed randomly through out our data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UZ0_wLC3uGF"
      },
      "source": [
        "# **Text- Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4urlrG2Gd3pB",
        "outputId": "d369a48f-35ad-49c3-ce7f-7d5454c704db"
      },
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Myvn6Sb1ekB"
      },
      "source": [
        "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "for i in range(len(data['review'])):\n",
        "  data['review'][i] = tokenizer.tokenize(data['review'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvbu0Ikv8zSR",
        "outputId": "5c46d5c9-891f-47b3-d122-c363f019c65f"
      },
      "source": [
        "print(len(data['review'][1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9yZfJumTT8"
      },
      "source": [
        "**Word Tokeniizing**(another method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdu2dF1K5kBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99719cc9-5c95-4573-a8f3-f73d2313b420"
      },
      "source": [
        "#data['review'] =  [word_tokenize(sentence) for sentence in data['review']]\n",
        "#print(len(data['review'][1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlSL5duMma_2"
      },
      "source": [
        "**Removing Stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVi3gtFxUMpp"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [word.lower() for word in data['review'][i] if word.lower() not in stop_words]\n",
        "print(len(data['review'][1]))\n",
        "# We have stemmed a lot of words \n",
        "print(data['review'][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCfE74pbmx15"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdibK8bFmAKb"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [ps.stem(word) for word in data['review'][i] ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uo6cisem1Re"
      },
      "source": [
        "**Lemmetizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJlxD_tFm582"
      },
      "source": [
        "lm = WordNetLemmatizer()\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [lm.lemmatize(word.lower()) for word in data['review'][i]]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuPUR2sLJM89"
      },
      "source": [
        "data['review'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "m4OlAjiTC6Qf",
        "outputId": "a1981ca4-c4cf-4f72-9208-afc37c0b7b37"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[one, review, mention, watch, 1, oz, episod, h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[wonder, littl, product, br, br, film, techniq...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[thought, wonder, way, spend, time, hot, summe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[basic, there', famili, littl, boy, jake, thin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[petter, mattei', love, time, money, visual, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[probabl, time, favorit, movi, stori, selfless...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[sure, would, like, see, resurrect, date, seah...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[show, amaz, fresh, innov, idea, 70', first, a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[encourag, posit, comment, film, look, forward...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[like, origin, gut, wrench, laughter, like, mo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  [one, review, mention, watch, 1, oz, episod, h...          1\n",
              "1  [wonder, littl, product, br, br, film, techniq...          1\n",
              "2  [thought, wonder, way, spend, time, hot, summe...          1\n",
              "3  [basic, there', famili, littl, boy, jake, thin...          0\n",
              "4  [petter, mattei', love, time, money, visual, s...          1\n",
              "5  [probabl, time, favorit, movi, stori, selfless...          1\n",
              "6  [sure, would, like, see, resurrect, date, seah...          1\n",
              "7  [show, amaz, fresh, innov, idea, 70', first, a...          0\n",
              "8  [encourag, posit, comment, film, look, forward...          0\n",
              "9  [like, origin, gut, wrench, laughter, like, mo...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FQBm0m85N2"
      },
      "source": [
        "AHH ! finally our cleaned data is here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xc3jMCaxt9p"
      },
      "source": [
        "data.to_csv('Cleaned_data.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcRJBkcCqRX9"
      },
      "source": [
        "# **Making The dictionary**\n",
        "we have used corpora module from gensim for this task "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGFZ-Oj_lNdl"
      },
      "source": [
        "from gensim import corpora\n",
        "review_dict= corpora.Dictionary(data['review'])\n",
        "print(review_dict)\n",
        "print(review_dict.token2id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F12uDqd7tX4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xviB38aTrlwC"
      },
      "source": [
        "# **Indexing the words from the dictionary** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDu5aCx4uU-7"
      },
      "source": [
        "def indexing(sentence):\n",
        "  return [review_dict.token2id[word] for word in sentence]\n",
        "data['review_index'] = data['review'].apply(indexing)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7psOU_CN_vJc"
      },
      "source": [
        "data['review_index'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By_WRGOJBZCl"
      },
      "source": [
        "We will be padding the sentences and shortening the long sentences so that the training in batches could be done more speedly "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rccMyy1FA-jU"
      },
      "source": [
        "def padding(sentence,seq_len):\n",
        "  features = np.zeros((len(sentence),seq_len),dtype = int)\n",
        "  for ii, review in enumerate(sentence):\n",
        "    if len(review) != 0:\n",
        "      features[ii,-len(review):] = np.array(review)[:seq_len]\n",
        "  return features"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3XIjHFuFl-v"
      },
      "source": [
        "# **Splitting the datatset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DttI3Or_GUW6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_v57msmFkCM",
        "outputId": "42d9a2fd-142b-42ba-f649-52c6b85b7325"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(data['review_index'],data['sentiment'],shuffle =True,test_size = 0.3,random_state = 15)\n",
        "print(Y_train.value_counts())\n",
        "print(Y_test.value_counts())\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    17512\n",
            "1    17488\n",
            "Name: sentiment, dtype: int64\n",
            "1    7512\n",
            "0    7488\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBdFiwcLI3bj"
      },
      "source": [
        "seq_len = 200\n",
        "X_train_pad = padding(X_train,seq_len)\n",
        "X_test_pad = padding(X_test,seq_len)\n",
        "Y_train = np.array(Y_train)\n",
        "Y_test = np.array(Y_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssj0LaE9LDmI"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNte0kx6KzKm"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(X_train_pad),torch.from_numpy(Y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test_pad),torch.from_numpy(Y_test))\n",
        "\n",
        "train_loader = DataLoader(train_data,shuffle= True,batch_size = 500)\n",
        "test_loader = DataLoader(test_data,shuffle = True,batch_size= 500)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBVI4HyQQjbo"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob = 0.5):\n",
        "    super(LSTM_net,self).__init__()\n",
        "    \n",
        "    self.output_size = output_size\n",
        "    self.hidden_dim = hidden_dim\n",
        "    \n",
        "    self.n_layers = n_layers\n",
        "    #embeddings\n",
        "    self.embeddings = nn.Embedding(vocab_size,embedding_dim)\n",
        "    #lstm\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,dropout = drop_prob,batch_first = True)\n",
        "    # We have used two fully connected layers \n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.fc1 = nn.Linear(hidden_dim,128)\n",
        "    self.fc2 = nn.Linear(128,output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.long()\n",
        "     #embedding and output of lstm\n",
        "    embedding = self.embeddings(x)\n",
        "    # the shape of the embedding tensor is  (x.shape,embedding_dim)\n",
        "    # these embeddings will go as input to our lstm \n",
        "    lstm_output,hidden = self.lstm(embedding,hidden)\n",
        "\n",
        "    lstm_output = lstm_output.contiguous().view(-1,self.hidden_dim)\n",
        "     #dropout and fully connected layers\n",
        "    lstm_output = self.dropout(lstm_output)\n",
        "    output = self.fc1(lstm_output)\n",
        "    output = self.dropout(output)\n",
        "    output = self.fc2(output)\n",
        "    #final output\n",
        "    output = self.sigmoid(output)\n",
        "    # reshaping to batch_size\n",
        "    output = output.view(batch_size,-1)\n",
        "    #getting the last batch of labels\n",
        "    output = output[ : ,-1] \n",
        "\n",
        "    return output,hidden\n",
        "    \n",
        "  def initialize_hidden(self,batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    hidden = (weight.new(self.n_layers,batch_size,self.hidden_dim).zero_().to(device),weight.new(self.n_layers,batch_size,self.hidden_dim).zero_().to(device))\n",
        "    return hidden"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epr2CjcongA0",
        "outputId": "46f7d93f-0d49-48d7-ab04-ddc786c4ee45"
      },
      "source": [
        "vocab_size = len(review_dict)+1\n",
        "output_size = 1\n",
        "embedding_dim = 200\n",
        "n_layers = 2\n",
        "hidden_dim = 256\n",
        "batch_size = 500\n",
        "model = LSTM_net(vocab_size,output_size,embedding_dim,hidden_dim,n_layers)\n",
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM_net(\n",
            "  (embeddings): Embedding(90078, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEPBXOvarfL4"
      },
      "source": [
        "# **Training our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY8cGG8BQjeq"
      },
      "source": [
        "lr = 0.001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = lr)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGeQzVY-bfsS",
        "outputId": "b2672db7-715e-4114-85e9-6b63fa405858"
      },
      "source": [
        "print(str(1))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krF6Qr8sQjkH",
        "outputId": "aa836e26-fd39-479d-eba2-396cdae43b38"
      },
      "source": [
        "epochs = 3\n",
        "clip = 5\n",
        "batch_counter = 1\n",
        "loss_at_epoch = []\n",
        "for i in range(epochs):\n",
        "  losses_train =[]\n",
        "  train_acc = 0\n",
        "  model.train()\n",
        "  #initializing the hidden states\n",
        "  h = model.initialize_hidden(batch_size)\n",
        "\n",
        "  for inputs,labels in train_loader:\n",
        "    h = tuple(e.data for e in h)\n",
        "    inputs,labels = inputs.to(device),labels.to(device)\n",
        "    #clearing all the accumulated gradients \n",
        "    model.zero_grad()\n",
        "    # calculating the output\n",
        "    output,h = model(inputs,h)\n",
        "    #loss\n",
        "    loss = criterion(output.squeeze(),labels.float())\n",
        "    losses_train.append(loss.item())\n",
        "    #accuracy\n",
        "    prediction = torch.round(output.squeeze())\n",
        "    train_acc += torch.sum(prediction == labels.squeeze()).item()\n",
        "    # Back propogation\n",
        "    loss.backward()\n",
        "    #tackling the problem of vanishing gradient descent\n",
        "    nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "    #updating the weights \n",
        "    optimizer.step()\n",
        "  #calculating the total loss at the end of a epoch\n",
        "  epoch_loss = np.mean(losses_train)\n",
        "  loss_at_epoch.append(epoch_loss)\n",
        "  #accuracy at the end of one epoch\n",
        "  epoch_acc = train_acc/len(train_loader.dataset)\n",
        "  print('Epoch :'+str(i+1))\n",
        "  print('loss = '+str(epoch_loss))\n",
        "  print(\"accuracy = \"+str(epoch_acc))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :1\n",
            "loss = 0.1835843203323228\n",
            "accuracy = 0.9306857142857143\n",
            "Epoch :2\n",
            "loss = 0.14789513253739903\n",
            "accuracy = 0.9467428571428571\n",
            "Epoch :3\n",
            "loss = 0.111133236810565\n",
            "accuracy = 0.9604285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCoR08kA0CkH"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyyj2KXnQjnQ",
        "outputId": "cb63da20-a961-4c37-a818-51d51d253ac3"
      },
      "source": [
        "test_loss = []\n",
        "test_acc = 0\n",
        "model.eval() \n",
        "for inputs,labels in test_loader:\n",
        "    h = tuple(e.data for e in h)\n",
        "    inputs,labels = inputs.to(device),labels.to(device)\n",
        "    #clearing all the accumulated gradients \n",
        "    model.zero_grad()\n",
        "    # calculating the output\n",
        "    output,h = model(inputs,h)\n",
        "    #loss\n",
        "    loss = criterion(output.squeeze(),labels.float())\n",
        "    test_loss.append(loss.item())\n",
        "    #accuracy\n",
        "    prediction = torch.round(output.squeeze())\n",
        "    test_acc += torch.sum(prediction == labels.squeeze()).item()\n",
        "loss = np.mean(test_loss)\n",
        "accuracy = test_acc/len(test_loader.dataset)\n",
        "print('loss'+str(loss))\n",
        "print('test accuracy'+str(accuracy))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss0.33933846751848856\n",
            "test accuracy0.8612666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diwK3g5_Qjp1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6e98_2SQjsa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
