{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Preprocessing",
      "provenance": [],
      "authorship_tag": "ABX9TyOiWfiCLeQwfuAAlsfUbt8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshgollen/NLPlay-with-transformers/blob/main/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5JG1gx4b_I1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE1mzhxrcfWP",
        "outputId": "8434b5a8-4a66-4dc4-ccd0-2c7a9398f0a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QzcZezKc2w1",
        "outputId": "15360203-3a0d-4895-968c-1df28e75cc7f"
      },
      "source": [
        "cd /content/drive/MyDrive/archive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/archive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsDIC-82dwUF"
      },
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFuqK_zJd7BJ"
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J9P-rxmeftb",
        "outputId": "5fac40fc-9559-4a44-836f-b26d66b532bb"
      },
      "source": [
        "print(data.head(10))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5  Probably my all-time favorite movie, a story o...  positive\n",
            "6  I sure would like to see a resurrection of a u...  positive\n",
            "7  This show was an amazing, fresh & innovative i...  negative\n",
            "8  Encouraged by the positive comments about this...  negative\n",
            "9  If you like original gut wrenching laughter yo...  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoBkyEmX5aJ"
      },
      "source": [
        " Let us first convert the sentiments into a form that could be understood by the computer. We can do it by assigning 1 calue to positive sentiment and 0 value for negative sentiment \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2TxkGWlYUnn"
      },
      "source": [
        "def Sentiment_conversion(sentiment):\n",
        "  if sentiment =='positive':\n",
        "    return  1\n",
        "  else : return 0 "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIJmfOKUewC8"
      },
      "source": [
        "data['sentiment'] = [Sentiment_conversion(sentiment) for sentiment in data['sentiment']]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QbMoeILZ4ka",
        "outputId": "f2361ba9-0fdc-43ba-f238-157627835f71"
      },
      "source": [
        "print(data['sentiment'].head(10))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "4    1\n",
            "5    1\n",
            "6    1\n",
            "7    0\n",
            "8    0\n",
            "9    1\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHw-jPmUaTr_",
        "outputId": "4b6ab778-05d6-4eb5-ddf8-dd82a651971b"
      },
      "source": [
        "print(pd.value_counts(data['sentiment']))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    25000\n",
            "0    25000\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vV1QTkAdcCS"
      },
      "source": [
        "We have equal numbers of sentiments distributed randomly through out our data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UZ0_wLC3uGF"
      },
      "source": [
        "# **Text- Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4urlrG2Gd3pB",
        "outputId": "4a05a617-9e5a-4092-d541-93d3af088c79"
      },
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9yZfJumTT8"
      },
      "source": [
        "**Word Tokeniizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdu2dF1K5kBG"
      },
      "source": [
        "data['review'] =  [word_tokenize(sentence) for sentence in data['review']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMeEetyAt6wm"
      },
      "source": [
        "We could also have used regular expression for word tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI9OfjkrE4Qn",
        "outputId": "2a5f8c5d-cadc-403d-a31d-87e519e5831c"
      },
      "source": [
        "print(len(data['review'][1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlSL5duMma_2"
      },
      "source": [
        "**Removing Stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVi3gtFxUMpp"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [word for word in data['review'][i] if word not in stop_words]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxfcUEZSU2-8",
        "outputId": "c316587c-e672-4be9-a4f7-094e3762072b"
      },
      "source": [
        "print(len(data['review'][1]))\n",
        "# We have stemmed a lot of words "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMxT3GkZVAet",
        "outputId": "9ac2209a-fa38-43b1-e2dd-a9ffa0876ead"
      },
      "source": [
        "print(data['review'][1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'wonderful', 'little', 'production', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'filming', 'technique', 'unassuming-', 'old-time-BBC', 'fashion', 'gives', 'comforting', ',', 'sometimes', 'discomforting', ',', 'sense', 'realism', 'entire', 'piece', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'actors', 'extremely', 'well', 'chosen-', 'Michael', 'Sheen', '``', 'got', 'polari', \"''\", 'voices', 'pat', '!', 'You', 'truly', 'see', 'seamless', 'editing', 'guided', 'references', 'Williams', \"'\", 'diary', 'entries', ',', 'well', 'worth', 'watching', 'terrificly', 'written', 'performed', 'piece', '.', 'A', 'masterful', 'production', 'one', 'great', 'master', \"'s\", 'comedy', 'life', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'realism', 'really', 'comes', 'home', 'little', 'things', ':', 'fantasy', 'guard', ',', 'rather', 'use', 'traditional', \"'dream\", \"'\", 'techniques', 'remains', 'solid', 'disappears', '.', 'It', 'plays', 'knowledge', 'senses', ',', 'particularly', 'scenes', 'concerning', 'Orton', 'Halliwell', 'sets', '(', 'particularly', 'flat', 'Halliwell', \"'s\", 'murals', 'decorating', 'every', 'surface', ')', 'terribly', 'well', 'done', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drooGHoLmhOM"
      },
      "source": [
        "**Removing Punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9aW6_igVMiC"
      },
      "source": [
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [word for word in data['review'][i] if word not in string.punctuation]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4gGEtwOlIBC",
        "outputId": "0ad322ad-2f88-42d7-f068-07553242f5a2"
      },
      "source": [
        "print(len(data['review'][1]))\n",
        "# We are getting better at this "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X886hcmLlcmY"
      },
      "source": [
        "I haven't followed the correct order first of all we should have removed the punctuation marks from our dataset .It worked unitl time is not an issue for us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCfE74pbmx15"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdibK8bFmAKb"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [ps.stem(word) for word in data['review'][i] ]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uo6cisem1Re"
      },
      "source": [
        "**Lemmetizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJlxD_tFm582"
      },
      "source": [
        "lm = WordNetLemmatizer()\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [lm.lemmatize(word) for word in data['review'][i]]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "m4OlAjiTC6Qf",
        "outputId": "44e7d357-d2be-4d8d-e71d-91bd0f939b85"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[one, review, mention, watch, 1, Oz, episod, '...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[A, wonder, littl, product, br, br, the, film,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[I, thought, wonder, way, spend, time, hot, su...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[basic, 's, famili, littl, boy, jake, think, '...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[petter, mattei, 's, ``, love, time, money, ''...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[probabl, all-tim, favorit, movi, stori, selfl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[I, sure, would, like, see, resurrect, date, s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[thi, show, amaz, fresh, innov, idea, 70, 's, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[encourag, posit, comment, film, I, look, forw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[If, like, origin, gut, wrench, laughter, like...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  [one, review, mention, watch, 1, Oz, episod, '...          1\n",
              "1  [A, wonder, littl, product, br, br, the, film,...          1\n",
              "2  [I, thought, wonder, way, spend, time, hot, su...          1\n",
              "3  [basic, 's, famili, littl, boy, jake, think, '...          0\n",
              "4  [petter, mattei, 's, ``, love, time, money, ''...          1\n",
              "5  [probabl, all-tim, favorit, movi, stori, selfl...          1\n",
              "6  [I, sure, would, like, see, resurrect, date, s...          1\n",
              "7  [thi, show, amaz, fresh, innov, idea, 70, 's, ...          0\n",
              "8  [encourag, posit, comment, film, I, look, forw...          0\n",
              "9  [If, like, origin, gut, wrench, laughter, like...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FQBm0m85N2"
      },
      "source": [
        "AHH ! finally our cleaned data is here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xc3jMCaxt9p"
      },
      "source": [
        "data.to_csv('Cleaned_data.csv')"
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}
