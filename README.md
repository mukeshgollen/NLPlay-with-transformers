# NLPlay-with-transformers

## Phase 1 :
Introduced us  to the field of Natural Language Processeing and looked at the  advancements in the past decade in the field.Also looked at the vast application of this field to many areas like speech recognition, sentiment analysis,voice assistants and many more uncountable applications.

**Basic- text Preprocessing**:
Explored various features of ```nltk```  a python library for basic text preprocessing like tokenization, stemming,lemmatization , removal of stop words , removal of punctuation etc 


Got familiar with the domain of Deep NLP and looked at many advancements in the Deep NLP.Nextly looked at the many techniques of Word Embedding like :
Frequency based ,count vectors, TF-TDF, Co -Occurence matrix ,Skip-gram model and Prediction based Vector.

Finally trained a Sentiment Classifier on the dataset ```IMDB Movie Reviews Dataset``` in which pre processing is done with the  help of ```nltk``` and the Bag of Words is used for vector genreation and a Feed forward neural network is trained in ```PyTorch```

Dived into the exciting domain of ```RNN``` ,looked at various types of Recurrent Neural Networks depending on our usage .Trained the classifier by using RNN. Looked at the limitations of RNN mainly Vanishing/Exploding Gradient Descent and short term dependece.Looked at the backgound of ```LSTM``` and trained the Classifier chieving a accuracy of 84 percent
## Phase 2:
Looked at the fundamentals of attention which is core to transformers.Familiarised with the concept and working of transformers.Looked at the working of ATTENTION models.
Fine tuned ```BERT``` and ```DistilBERT``` on the ```IMDB``` dataset for sentiment Analysis achieving a accuracy of 89 percent.```DistilBERT``` os shorter version of ```BERT``` having apporx. half layers and achieving the same performanceor the same attention mask with the tuning time reduced by half.
## Phase 3:
So far the most interesting phase ,this phase covered text generation transformer based model like ```GPT-2``` and ```T-5``` .
Created a Custom Dataset from fields like Sciene,Finance and Entertainment.Generated paragraphs using ```GPT-2``` and ```T-5```
Evaluated the Output generated by these models by calculating the ```BLEU``` Score 
### Some Fun Moments : 
Sometime the output text generated by the model contained random links to some abstract reseasrch papers,while many times it was creating it's own derivations which didn't made any sense.they had their own theories on investing and many other fun moments
