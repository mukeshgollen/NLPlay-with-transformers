# NLPlay-with-transformers

## Phase 1 :
Introduced us  to the field of Natural Language Processeing and looked at the  advancements in the past decade in the field.Also looked at the vast application of this field to many areas like speech recognition, sentiment analysis,voice assistants and many more uncountable applications.

**Basic- text Preprocessing**:
Explored various features of ```nltk```  a python library for basic text preprocessing like tokenization, stemming,lemmatization , removal of stop words , removal of punctuation etc 

### Week 2:
Got familiar with the domain of Deep NLP and looked at many advancements in the Deep NLP.Nextly looked at the many techniques of Word Embedding like :
Frequency based ,count vectors, TF-TDF, Co -Occurence matrix ,Skip-gram model and Prediction based Vector.

Finally trained a Sentiment Classifier on the dataset ```IMDB Movie Reviews Dataset``` in which pre processing is done with the  help of ```nltk``` and the Bag of Words is used for vector genreation and a Feed forward neural network is trained in ```PyTorch```
### Week 3:
Dived into the exciting domain of ```RNN``` ,looked at various types of Recurrent Neural Networks depending on our usage .Trained the classifier by using RNN. Looked at the limitations of RNN mainly Vanishing/Exploding Gradient Descent and short term dependece.Looked at the backgound of ```LSTM``` and trained the Classifier chieving a accuracy of 84 percent
## Phase 2:
Looked at the fundamentals of attention which is core to transformers.Familiarised with the concept and working of transformers.Looked at the working of ATTENTION models.
Fine tuned ```BERT``` and ```DistilBERT``` on the ```IMDB``` dataset for sentiment Analysis achieving a accuracy of 89 percent

## Phase 3:
So far the most interesting phase ,this phase covered text generation transformer based model like ```GPT-2``` and ```T-5``` 
Created a custom dataset of articles from vast fields.
