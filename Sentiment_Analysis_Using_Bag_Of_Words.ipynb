{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Using_Bag_Of_Words",
      "provenance": [],
      "authorship_tag": "ABX9TyOFobbxZHs7mcbvurktza9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshgollen/NLPlay-with-transformers/blob/main/Sentiment_Analysis_Using_Bag_Of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5JG1gx4b_I1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE1mzhxrcfWP",
        "outputId": "0bf109db-32b0-4349-893f-895bec0dca0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QzcZezKc2w1",
        "outputId": "ac35efbb-036a-4c0b-9fd3-ba33adf20fa1"
      },
      "source": [
        "cd /content/drive/MyDrive/archive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/archive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsDIC-82dwUF"
      },
      "source": [
        "import pandas as pd\n",
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFuqK_zJd7BJ"
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J9P-rxmeftb",
        "outputId": "db1b493f-1b81-4292-e9c3-2bf5ac4d0b66"
      },
      "source": [
        "print(data.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5  Probably my all-time favorite movie, a story o...  positive\n",
            "6  I sure would like to see a resurrection of a u...  positive\n",
            "7  This show was an amazing, fresh & innovative i...  negative\n",
            "8  Encouraged by the positive comments about this...  negative\n",
            "9  If you like original gut wrenching laughter yo...  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoBkyEmX5aJ"
      },
      "source": [
        " Let us first convert the sentiments into a form that could be understood by the computer. We can do it by assigning 1 calue to positive sentiment and 0 value for negative sentiment \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2TxkGWlYUnn"
      },
      "source": [
        "def Sentiment_conversion(sentiment):\n",
        "  if sentiment =='positive':\n",
        "    return  1\n",
        "  else : return 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIJmfOKUewC8"
      },
      "source": [
        "data['sentiment'] = [Sentiment_conversion(sentiment) for sentiment in data['sentiment']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QbMoeILZ4ka",
        "outputId": "86e095ec-6b6e-4d55-98dd-5437c6af87d5"
      },
      "source": [
        "print(data['sentiment'].head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "4    1\n",
            "5    1\n",
            "6    1\n",
            "7    0\n",
            "8    0\n",
            "9    1\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHw-jPmUaTr_",
        "outputId": "fb777329-b93d-42d1-e3af-e0cf529d7d12"
      },
      "source": [
        "print(pd.value_counts(data['sentiment']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    25000\n",
            "0    25000\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vV1QTkAdcCS"
      },
      "source": [
        "We have equal numbers of sentiments distributed randomly through out our data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UZ0_wLC3uGF"
      },
      "source": [
        "# **Text- Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4urlrG2Gd3pB",
        "outputId": "47756c5a-c1c5-4f80-de9a-af1ecc65bf3d"
      },
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9yZfJumTT8"
      },
      "source": [
        "**Word Tokeniizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdu2dF1K5kBG"
      },
      "source": [
        "data['review'] =  [word_tokenize(sentence) for sentence in data['review']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMeEetyAt6wm"
      },
      "source": [
        "We could also have used regular expression for word tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI9OfjkrE4Qn",
        "outputId": "ff14de60-3d81-424d-b8d4-f672c4794001"
      },
      "source": [
        "print(len(data['review'][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlSL5duMma_2"
      },
      "source": [
        "**Removing Stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVi3gtFxUMpp"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [word for word in data['review'][i] if word not in stop_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxfcUEZSU2-8",
        "outputId": "034b22db-886e-4ba2-f567-b428dbe1914e"
      },
      "source": [
        "print(len(data['review'][1]))\n",
        "# We have stemmed a lot of words "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMxT3GkZVAet",
        "outputId": "f68e54f9-58e9-469b-f1ff-5074c2572143"
      },
      "source": [
        "print(data['review'][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'wonderful', 'little', 'production', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'filming', 'technique', 'unassuming-', 'old-time-BBC', 'fashion', 'gives', 'comforting', ',', 'sometimes', 'discomforting', ',', 'sense', 'realism', 'entire', 'piece', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'actors', 'extremely', 'well', 'chosen-', 'Michael', 'Sheen', '``', 'got', 'polari', \"''\", 'voices', 'pat', '!', 'You', 'truly', 'see', 'seamless', 'editing', 'guided', 'references', 'Williams', \"'\", 'diary', 'entries', ',', 'well', 'worth', 'watching', 'terrificly', 'written', 'performed', 'piece', '.', 'A', 'masterful', 'production', 'one', 'great', 'master', \"'s\", 'comedy', 'life', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'The', 'realism', 'really', 'comes', 'home', 'little', 'things', ':', 'fantasy', 'guard', ',', 'rather', 'use', 'traditional', \"'dream\", \"'\", 'techniques', 'remains', 'solid', 'disappears', '.', 'It', 'plays', 'knowledge', 'senses', ',', 'particularly', 'scenes', 'concerning', 'Orton', 'Halliwell', 'sets', '(', 'particularly', 'flat', 'Halliwell', \"'s\", 'murals', 'decorating', 'every', 'surface', ')', 'terribly', 'well', 'done', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drooGHoLmhOM"
      },
      "source": [
        "**Removing Punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9aW6_igVMiC"
      },
      "source": [
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [word for word in data['review'][i] if word not in string.punctuation]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4gGEtwOlIBC",
        "outputId": "b6cfa318-c490-4d0e-f6ea-4af38807e8c8"
      },
      "source": [
        "print(len(data['review'][1]))\n",
        "# We are getting better at this "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X886hcmLlcmY"
      },
      "source": [
        "I haven't followed the correct order first of all we should have removed the punctuation marks from our dataset .It worked unitl time is not an issue for us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCfE74pbmx15"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdibK8bFmAKb"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [ps.stem(word) for word in data['review'][i] ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uo6cisem1Re"
      },
      "source": [
        "**Lemmetizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJlxD_tFm582"
      },
      "source": [
        "lm = WordNetLemmatizer()\n",
        "for i in range(len(data['review'] )):\n",
        "  pd.set_option('mode.chained_assignment',None)\n",
        "  data['review'][i] = [lm.lemmatize(word) for word in data['review'][i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FQBm0m85N2"
      },
      "source": [
        "AHH ! finally our cleaned data is here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PlKoKRE1vOxm",
        "outputId": "9b0d1a61-5527-4184-c593-a746c3406005"
      },
      "source": [
        "Cleaned_data = pd.DataFrame(data['review'])\n",
        "Cleaned_data.join(data['sentiment'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[one, review, mention, watch, 1, Oz, episod, '...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[A, wonder, littl, product, br, br, the, film,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[I, thought, wonder, way, spend, time, hot, su...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[basic, 's, famili, littl, boy, jake, think, '...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[petter, mattei, 's, ``, love, time, money, ''...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>[I, thought, movi, right, good, job, It, n't, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>[bad, plot, bad, dialogu, bad, act, idiot, dir...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>[I, cathol, taught, parochi, elementari, schoo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>[I, 'm, go, disagre, previou, comment, side, m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>[No, one, expect, star, trek, movi, high, art,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      [one, review, mention, watch, 1, Oz, episod, '...          1\n",
              "1      [A, wonder, littl, product, br, br, the, film,...          1\n",
              "2      [I, thought, wonder, way, spend, time, hot, su...          1\n",
              "3      [basic, 's, famili, littl, boy, jake, think, '...          0\n",
              "4      [petter, mattei, 's, ``, love, time, money, ''...          1\n",
              "...                                                  ...        ...\n",
              "49995  [I, thought, movi, right, good, job, It, n't, ...          1\n",
              "49996  [bad, plot, bad, dialogu, bad, act, idiot, dir...          0\n",
              "49997  [I, cathol, taught, parochi, elementari, schoo...          0\n",
              "49998  [I, 'm, go, disagre, previou, comment, side, m...          0\n",
              "49999  [No, one, expect, star, trek, movi, high, art,...          0\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xc3jMCaxt9p"
      },
      "source": [
        "Cleaned_data.to_csv('Cleaned_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}